{
  "lang": "en",
  "meta": {
    "title": "Fabrice Matulic, PhD - Homepage",
    "description": "Homepage of Fabrice Matulic, Senior Researcher in HCI and Applied AI"
  },
  "header": {
    "name": "Homepage of Fabrice Matulic, Ph.D."
  },
  "nav": {
    "lang_switch_text": "日本語",
    "lang_switch_target": "ja"
  },
  "intro": {
    "greeting": "Welcome!",
    "text": "I am a researcher focusing on Human-Computer Interaction (HCI), particularly in the areas of pen & touch interaction, extended reality (XR), embodied interaction, and document engineering. This page highlights my projects, publications, and patents."
  },
  "teaser": {
    "alt_text": "Research Highlights Animation"
  },
  "sections": {
    "categories": "Filter by Category:",
    "patents": "Patents",
    "contact": "Contact"
  },
  "categories": [
    { "id": "all", "name": "All", "logo": "" },
    { "id": "pen-touch", "name": "Pen & Touch", "logo": "img/logos/pen-touch.png" },
    { "id": "xr", "name": "Extended Reality (XR)", "logo": "img/logos/xr.png" },
    { "id": "embodied", "name": "Embodied Interaction", "logo": "img/logos/embodied.png" },
    { "id": "doc-eng", "name": "Document Engineering", "logo": "img/logos/doc-eng.png" }
  ],
  "institutions": [
      { "id": "inst1", "name": "Institution Name 1", "logo": "img/logos/institution1.png", "url": "http://institution1.example.com" },
      { "id": "inst2", "name": "Institution Name 2", "logo": "img/logos/institution2.png", "url": "http://institution2.example.com" }
  ],
"publications": [
    {
      "id": "pub_gi24",
      "type": "paper",
      "title": "Above-Screen Fingertip Tracking with a Phone in Virtual Reality",
      "authors": "Fabrice Matulic, Taiga Kashima, Deniz Beker, Daichi Suzuo, Hiroshi Fujiwara and Daniel Vogel",
      "venue": "Proc. Graphics Interface (GI 2024), Halifax, NS, Canada, May 2024",
      "year": 2024,
      "pdf": "pubs/GI2024.pdf",
      "video": "https://www.youtube.com/watch?v=puchckJFSCY",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_siggraphasia23tc",
      "type": "paper",
      "title": "Interactive Material Annotation on 3D Scanned Models leveraging Color-Material Correlation",
      "authors": "Wataru Kawabe, Taisuke Hashimoto, Fabrice Matulic, Takeo Igarashi, Keita Higuchi",
      "venue": "SIGGRAPH Asia 2023 Technical Communications",
      "year": 2023,
      "pdf": "pubs/SIGGRAPHAsia2023TC.pdf",
      "video": "https://www.youtube.com/watch?v=qwU-OiYsZ-g",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_iss23",
      "type": "paper",
      "title": "Interactive 3D Annotation of Objects in Moving Videos from Sparse Multi-view Frames",
      "authors": "Kotaro Oomori, Wataru Kawabe, Fabrice Matulic, Takeo Igarashi, Keita Higuchi",
      "venue": "Proc. of the ACM on Human-Computer Interaction, Volume 7, Issue ISS (ISS 2023), Pittsburgh, USA, November 2023",
      "year": 2023,
      "pdf": "pubs/ISS2023.pdf",
      "video": "https://www.youtube.com/watch?v=PT-PElgtQcI",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_gi23",
      "type": "paper",
      "title": "Pen+Touch+Midair: Cross-Space Hybrid Bimanual Interaction on Horizontal Surfaces in Virtual Reality",
      "authors": "Fabrice Matulic and Daniel Vogel",
      "venue": "Proc. Graphics Interface (GI 2023), Victoria, BC, Canada, May 2023",
      "year": 2023,
      "pdf": "pubs/GI2023.pdf",
      "video": "https://youtu.be/iHgpMMFVtgg",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_chi23",
      "type": "paper",
      "title": "Phone Sleight of Hand: Finger-Based Dexterous Gestures for Physical Interaction with Mobile Phones",
      "authors": "Yen-Ting Yeh, Fabrice Matulic and Daniel Vogel",
      "venue": "Proc. Conference on Human Factors in Computing Systems (CHI 2023), Hamburg, Germany, April 2023",
      "year": 2023,
      "pdf": "pubs/CHI2023.pdf",
      "video": "https://www.youtube.com/watch?v=U0kusO7hH1g",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_chi23lbw",
      "type": "poster",
      "title": "Above-Screen Fingertip Tracking with a Phone in Virtual Reality",
      "authors": "Fabrice Matulic, Taiga Kashima, Deniz Beker, Daichi Suzuo, Hiroshi Fujiwara and Daniel Vogel",
      "venue": "Proc. Conference on Human Factors in Computing Systems Extended Abstracts (CHI 2023 Late Breaking Work), Hamburg, Germany, April 2023",
      "year": 2023,
      "pdf": "pubs/CHI2023LBW.pdf",
      "video": "https://www.youtube.com/watch?v=hNPKkb-ml6k",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_chi23lbw2",
      "type": "poster",
      "title": "Interactive Generation of Image Variations for Copy-Paste Data Augmentation",
      "authors": "Keita Higuchi, Taiyo Mizuhashi, Fabrice Matulic and Takeo Igarashi",
      "venue": "Proc. Conference on Human Factors in Computing Systems Extended Abstracts (CHI 2023 Late Breaking Work), Hamburg, Germany, April 2023",
      "year": 2023,
      "pdf": "pubs/CHI2023LBW2.pdf",
      "video": "https://www.youtube.com/watch?v=HklROgx4iNA",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_chi22lbw",
      "type": "poster",
      "title": "Terrain Modelling with a Pen & Touch Tablet and Mid-Air Gestures in Virtual Reality",
      "authors": "Fabrice Matulic and Daniel Vogel",
      "venue": "Proc. Conference on Human Factors in Computing Systems Extended Abstracts (CHI 2022 Late Breaking Work), New Orleans, USA, April 2022",
      "year": 2022,
      "pdf": "pubs/CHI2022LBW.pdf",
      "video": "https://www.youtube.com/watch?v=X32PX08XXYQ",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_iss21a",
      "type": "paper",
      "title": "Typealike: Near-Keyboard Hand Postures for Expanded Laptop Interaction",
      "authors": "Nalin Chhibber, Hemant Bhaskar Surale, Fabrice Matulic and Daniel Vogel",
      "venue": "Proc. of the ACM on Human-Computer Interaction, Volume 5, Issue ISS (ISS 2021), Łódź, Poland, November 2021",
      "year": 2021,
      "pdf": "pubs/ISS2021a.pdf",
      "video": "https://www.youtube.com/watch?v=QyfMicxQH84",
      "doi": null,
      "notes": "Honourable Mention Award"
    },
    {
      "id": "pub_iss21b",
      "type": "paper",
      "title": "HybridPointing for Touch: Switching Between Absolute and Relative Pointing on Large Touch Screens",
      "authors": "Terence Dickson, Rina R. Wehbe, Fabrice Matulic, Daniel Vogel",
      "venue": "Proc. of the ACM on Human-Computer Interaction, Volume 5, Issue ISS (ISS 2021), Łódź, Poland, November 2021",
      "year": 2021,
      "pdf": "pubs/ISS2021b.pdf",
      "video": "https://www.youtube.com/watch?v=drMl3CTLrP0",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_springer21",
      "type": "paper",
      "title": "Deep Learning-Based Hand Posture Recognition for Pen Interaction Enhancement",
      "authors": "Fabrice Matulic and Daniel Vogel",
      "venue": "Artificial Intelligence for Human Computer Interaction: A Modern Approach, Springer HCIS 2021",
      "year": 2021,
      "pdf": "https://link.springer.com/chapter/10.1007/978-3-030-82681-9_7",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_chi21",
      "type": "paper",
      "title": "Phonetroller: Visual Representations of Fingers for Precise Touch Input with Mobile Phones in VR",
      "authors": "Fabrice Matulic, Aditya Ganeshan, Hiroshi Fujiwara and Daniel Vogel",
      "venue": "Proc. Conference on Human Factors in Computing Systems (CHI 2021), Yokohama, Japan, May 2021",
      "year": 2021,
      "pdf": "pubs/CHI2021.pdf",
      "video": "https://www.youtube.com/watch?v=fMeDbZRSVAE",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_chi20",
      "type": "paper",
      "title": "PenSight: Enhanced Interaction with a Pen-Top Camera",
      "authors": "Fabrice Matulic, Riku Arakawa, Brian Vogel and Daniel Vogel",
      "venue": "Proc. Conference on Human Factors in Computing Systems (CHI 2020), Honolulu, HI, USA, April 2020",
      "year": 2020,
      "pdf": "pubs/CHI2020.pdf",
      "video": "https://www.youtube.com/watch?v=x4cobX5RTc8",
      "doi": null,
      "notes": "Best Paper Award"
    },
    {
      "id": "pub_iss19",
      "type": "paper",
      "title": "Eliciting Pen-Holding Postures for General Input with Suitability for EMG Armband Detection",
      "authors": "Fabrice Matulic, Brian Vogel, Naoki Kimura and Daniel Vogel",
      "venue": "Proc. ACM International Conference on Interactive Surfaces and Spaces (ISS 2019), Deajeon, Republic of Korea, November 2019",
      "year": 2019,
      "pdf": "pubs/ISS2019.pdf",
      "video": "https://www.youtube.com/watch?v=yNXyQYevaBY",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_chi19",
      "type": "paper",
      "title": "Experimental Analysis of Barehand Mid-air Mode-Switching Techniques in Virtual Reality",
      "authors": "Hemant Bhaskar Surale, Fabrice Matulic and Daniel Vogel",
      "venue": "Proc. Conference on Human Factors in Computing Systems (CHI 2019), Glasgow, Scotland, UK, May 2019",
      "year": 2019,
      "pdf": "pubs/CHI2019.pdf",
      "video": "https://www.youtube.com/watch?v=2TKuZsPFjoI",
      "doi": null,
      "notes": "Honourable Mention Award"
    },
    {
      "id": "pub_chi19lbw",
      "type": "poster",
      "title": "Extending Discrete Verbal Commands with Continuous Speech for Flexible Robot Control",
      "authors": "Naoya Yoshimura, Hironori Yoshida, Fabrice Matulic and Takeo Igarashi",
      "venue": "Proc. Extended Abstracts on Human Factors in Computing Systems (CHI 2019), Glasgow, Scotland, UK, May 2019",
      "year": 2019,
      "pdf": "pubs/CHI2019LBW.pdf",
      "video": "https://youtu.be/0dCXx-0sGUY",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_chi19hcmlws",
      "type": "workshop",
      "title": "Enabling Customer-Driven Learning and Customisation Processes for ML-Based Domestic Robots",
      "authors": "Fabrice Matulic, Yuta Kikuchi and Jason Naradowsky",
      "venue": "HCML Perspectives Workshop at Conference on Human Factors in Computing Systems (CHI 2019), Glasgow, Scotland, UK, May 2019",
      "year": 2019,
      "pdf": "pubs/CHI2019HCMLWorkshop.pdf",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "link_ceatec18",
      "type": "link",
      "title": "Autonomous Tidying-up Robot System, CEATEC JAPAN 2018",
      "authors": null,
      "venue": "CEATEC JAPAN 2018",
      "year": 2018,
      "pdf": "https://projects.preferred.jp/tidying-up-robot/en/",
      "video": null,
      "doi": null,
      "notes": "Project page"
    },
    {
      "id": "pub_iss18",
      "type": "paper",
      "title": "ColourAIze: AI-Driven Colourisation of Paper Drawings with Interactive Projection System",
      "authors": "Fabrice Matulic",
      "venue": "Proc. ACM International Conference on Interactive Surfaces and Spaces (ISS 2018), Tokyo, Japan, November 2018",
      "year": 2018,
      "pdf": "pubs/ISS2018.pdf",
      "video": "https://www.youtube.com/watch?v=DYZzhK0ywiQ",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_uist18",
      "type": "paper",
      "title": "Unimanual Pen+Touch Input Using Variations of Precision Grip Postures",
      "authors": "Drini Cami, Fabrice Matulic, Richard G. Calland, Brian Vogel, Daniel Vogel",
      "venue": "Proc. ACM Symposium on User Interface Software and Technology (UIST 2018), Berlin, Germany, October 2018",
      "year": 2018,
      "pdf": "pubs/UIST2018.pdf",
      "video": "https://youtu.be/RqpRRSvNbAM",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_chi18",
      "type": "paper",
      "title": "Multiray: Multi-Finger Raycasting for Large Displays",
      "authors": "Fabrice Matulic, Daniel Vogel",
      "venue": "Proc. Conference on Human Factors in Computing Systems (CHI 2018), Montréal, QC, Canada, April 2018",
      "year": 2018,
      "pdf": "pubs/CHI2018.pdf",
      "video": "videos/CHI2018.mp4",
      "doi": null,
      "notes": "Honourable Mention Award"
    },
    {
      "id": "pub_iss17",
      "type": "paper",
      "title": "Hand Contact Shape Recognition for Posture-Based Tabletop Widgets and Interaction",
      "authors": "Fabrice Matulic, Daniel Vogel and Raimund Dachselt",
      "venue": "Proc. ACM International Conference on Interactive Surfaces and Spaces (ISS 2017), Brighton, UK, October 2017",
      "year": 2017,
      "pdf": "pubs/ISS2017.pdf",
      "video": "videos/ISS2017.mp4",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_chi17",
      "type": "paper",
      "title": "Experimental Analysis of Mode Switching Techniques in Touch-based User Interfaces",
      "authors": "Hemant Bhaskar Surale, Fabrice Matulic and Daniel Vogel",
      "venue": "Proc. Conference on Human Factors in Computing Systems (CHI 2017), Denver, CO, USA, May 2017",
      "year": 2017,
      "pdf": "pubs/CHI2017.pdf",
      "video": "videos/CHI2017.mp4",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_chi16lbw_eip",
      "type": "poster",
      "title": "Embodied Interactions for Novel Immersive Presentational Experiences",
      "authors": "Fabrice Matulic, Lars Engeln, Christoph Träger and Raimund Dachselt",
      "venue": "Proc. Extended Abstracts on Human Factors in Computing Systems (CHI 2016), San Jose, CA, USA, May 2016",
      "year": 2016,
      "pdf": "pubs/CHI2016LBW_EIP.pdf",
      "video": "videos/EmbeddedPres.mp4",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_chi16lbw_sp",
      "type": "poster",
      "title": "Smart Ubiquitous Projection: Discovering Surfaces for the Projection of Adaptive Content",
      "authors": "Fabrice Matulic, Wolfgang Büschel, Michael Ying Yang, Stephan Ihrke, Anmol Ramraika, Carsten Rother and Raimund Dachselt",
      "venue": "Proc. Extended Abstracts on Human Factors in Computing Systems (CHI 2016), San Jose, CA, USA, May 2016",
      "year": 2016,
      "pdf": "pubs/CHI2016LBW_SP.pdf",
      "video": "videos/SmartProj.mp4",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_its15wb",
      "type": "paper",
      "title": "Eyes-Free Touch Command Support for Pen-Based Digital Whiteboards via Handheld Devices",
      "authors": "Fabrice Matulic, Maria Husmann, Seraiah Walter and Moira C. Norrie",
      "venue": "Proc. ACM Interactive Tabletops and Surfaces 2015 Conference (ITS 2015), Funchal, Madeira, Portugal, November 2015",
      "year": 2015,
      "pdf": "pubs/ITS2015Whiteboard.pdf",
      "video": "videos/ITS2015Whiteboard.mp4",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_its15ws",
      "type": "workshop",
      "title": "Interaction Design for Large Vertical vs. Horizontal Displays: Open Issues",
      "authors": "Fabrice Matulic, Ulrich von Zadow and Raimund Dachselt",
      "venue": "Workshop on Interaction on Large Displays at ACM Interactive Tabletops and Surfaces 2015 Conference (ITS 2015), Funchal, Madeira, Portugal, November 2015",
      "year": 2015,
      "pdf": "pubs/ITS2015Workshop.pdf",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_its15bl",
      "type": "paper",
      "title": "BodyLenses – Embodied Magic Lenses and Personal Territories for Wall Displays",
      "authors": "Ulrike Kister, Patrick Reipschläger, Fabrice Matulic and Raimund Dachselt",
      "venue": "Proc. ACM Interactive Tabletops and Surfaces 2015 Conference (ITS 2015), Funchal, Madeira, Portugal, November 2015",
      "year": 2015,
      "pdf": "pubs/ITS2015Bodylenses.pdf",
      "video": "videos/ITS2015Bodylenses.mp4",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_its14",
      "type": "paper",
      "title": "Spatial Querying of Geographical Data with Pen-Input Scopes",
      "authors": "Fabrice Matulic, David Caspar and Moira C. Norrie",
      "venue": "Proc. ACM Interactive Tabletops and Surfaces 2014 Conference (ITS 2014), Dresden, Germany, November 2014",
      "year": 2014,
      "pdf": "pubs/ITS2014.pdf",
      "video": "videos/ITS2014.avi",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_uist14",
      "type": "paper",
      "title": "Sensing Techniques for Tablet+Stylus Interaction",
      "authors": "Ken Hinckley, Michel Pahud, Hrvoje Benko, Pourang Irani, François Guimbretière, Marcel Gavriliu, Xiang 'Anthony' Chen, Fabrice Matulic, Bill Buxton and Andy Wilson",
      "venue": "Proc. ACM Symposium on User Interface Software and Technology (UIST 2014), Honolulu, HI, USA, October 2014",
      "year": 2014,
      "pdf": "http://dl.acm.org/citation.cfm?id=2647379",
      "video": "https://youtu.be/9dgHgHQSuuY",
      "doi": null,
      "notes": "Best Paper Award"
    },
    {
      "id": "pub_thesis14",
      "type": "thesis",
      "title": "Towards Document Engineering on Pen and Touch-Operated Interactive Tabletops",
      "authors": "Fabrice Matulic",
      "venue": "ETH PhD Thesis 2014",
      "year": 2014,
      "pdf": "pubs/Thesis.pdf",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_mipr13",
      "type": "paper",
      "title": "QUEST: Towards a Multi-Modal CBIR Framework Combining Query-by-Example, Query-by-Sketch, and Text Search",
      "authors": "Ihab Al Kabary, Ivan Giangreco, Heiko Schuldt, Fabrice Matulic and Moira C. Norrie",
      "venue": "Proc. 9th IEEE International Workshop on Multimedia Information Processing and Retrieval (IEEE MIPR2013), Anaheim CA, USA, December 2013",
      "year": 2013,
      "pdf": "pubs/MIPR.pdf",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_its13",
      "type": "paper",
      "title": "Pen and Touch Gestural Environment for Document Editing on Interactive Tabletops",
      "authors": "Fabrice Matulic and Moira C. Norrie",
      "venue": "Proc. ACM Interactive Tabletops and Surfaces 2013 Conference (ITS 2013), St Andrews, Scotland, UK, October 2013",
      "year": 2013,
      "pdf": "pubs/ITS2013.pdf",
      "video": "videos/ITS2013.mp4",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_chi13ws",
      "type": "workshop",
      "title": "Beyond WIMP: Designing NUIs to Support Productivity Document Tasks",
      "authors": "Fabrice Matulic",
      "venue": "Blended Interaction, Envisioning Future Collaborative Interactive Spaces, CHI 2013 Workshop, Paris, France, April 2013",
      "year": 2013,
      "pdf": "pubs/CHI2013WS.pdf",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_chi13wip",
      "type": "poster",
      "title": "Gesture-Supported Document Creation on Pen and Touch Tabletops",
      "authors": "Fabrice Matulic, Moira C. Norrie, Ihab Al Kabary and Heiko Schuldt",
      "venue": "CHI 2013 Extended Abstracts on Human Factors in Computing Systems, Works-in-Progress, Paris, France, April 2013",
      "year": 2013,
      "pdf": "pubs/CHI2013WIP.pdf",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "link_sf1_eco",
      "type": "link",
      "title": "Featured on SF 1 'Eco' (Swiss TV)",
      "authors": null,
      "venue": "SF 1 'Eco'",
      "year": 2012,
      "pdf": "http://www.videoportal.sf.tv/video?id=9fa222d4-63cd-4d5f-b5a5-a533ea8b6310",
      "video": null,
      "doi": null,
      "notes": "TV Feature (Active Reading App)"
    },
     {
      "id": "link_sf1_einstein",
      "type": "link",
      "title": "Featured on SF 1 'Einstein' (Swiss TV)",
      "authors": null,
      "venue": "SF 1 'Einstein'",
      "year": 2011,
      "pdf": "videos/SF_Einstein.mkv",
      "video": null,
      "doi": null,
      "notes": "TV Feature (Active Reading App)"
    },
    {
      "id": "link_uml_tool",
      "type": "link",
      "title": "Student Lab Project: UML Diagram Tool",
      "authors": null,
      "venue": "Student Project Lab (ETH)",
      "year": null,
      "pdf": "http://www.youtube.com/watch?v=hsZOsjf5un4",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_its12",
      "type": "paper",
      "title": "Empirical Evaluation of Uni- and Bimodel Pen and Touch Interaction Properties on Digital Tabletops",
      "authors": "Fabrice Matulic and Moira C. Norrie",
      "venue": "Proc. ACM Interactive Tabletops and Surfaces Conference (ITS 2012), Cambridge (MA), USA, November 2012",
      "year": 2012,
      "pdf": "pubs/ITS2012.pdf",
      "video": "videos/PT_Study.mp4",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_uist12ds",
      "type": "poster",
      "title": "Towards Document Engineering on Pen and Touch-Operated Interactive Tabletops",
      "authors": "Fabrice Matulic",
      "venue": "Doctoral Symposium of the 25th ACM Symposium on User Interface Software and Technology (UIST 2012), Cambridge (MA), USA, October 2012",
      "year": 2012,
      "pdf": "pubs/UIST2012DS.pdf",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_us20120224232",
      "type": "patent",
      "title": "US Patent Application 20120224232: Image Forming Apparatus, Electronic Mail Delivery Server, and Information Processing Apparatus",
      "authors": null,
      "venue": "US Patent Application",
      "year": 2012,
      "pdf": "http://www.freepatentsonline.com/y2012/0224232.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_avi12",
      "type": "paper",
      "title": "Supporting Active Reading on Pen and Touch-Operated Tabletops",
      "authors": "Fabrice Matulic and Moira C. Norrie",
      "venue": "Proc. International Working Conference on Advanced Visual Interfaces (AVI 2012), Capri Island, Italy, May 2012",
      "year": 2012,
      "pdf": "pubs/AVI2012.pdf",
      "video": "videos/Supporting_AR.mp4",
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_doceng11",
      "type": "paper",
      "title": "Adaptive Layout Template for Effective Web Content Presentation in Large-Screen Contexts",
      "authors": "Michael Nebeling, Fabrice Matulic, Lucas Streit and Moira C. Norrie",
      "venue": "Proc. 2011 ACM Symposium on Document Engineering (DocEng 2011), Mountain View, CA, USA, September 2011",
      "year": 2011,
      "pdf": "pubs/DocEng2011.pdf",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_chi11",
      "type": "paper",
      "title": "Metrics for the Evaluation of News Site Content Layout in Large-Screen Contexts",
      "authors": "Michael Nebeling, Fabrice Matulic and Moira C. Norrie",
      "venue": "Proc. ACM Conference on Human Factors in Computing Systems (CHI 2011), Vancouver, BC, Canada, May 2011",
      "year": 2011,
      "pdf": "pubs/CHI2011.pdf",
      "video": null,
      "doi": null,
      "notes": "Honorable Mention Award"
    },
    {
      "id": "pub_jdim09",
      "type": "paper",
      "title": "Image-Based Technique To Select Visually Salient Pages In Large Documents",
      "authors": "Fabrice Matulic",
      "venue": "Journal of Digital Information Management, Vol. 7, Issue 5, Oct. 2009",
      "year": 2009,
      "pdf": "pubs/JDIM2009.pdf",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2009093628",
      "type": "patent",
      "title": "Japan Patent 2009-093628: Document utilization support device, document utilization support method and document utilization support program",
      "authors": null,
      "venue": "Japan Patent",
      "year": 2009,
      "pdf": "http://www.freepatentsonline.com/JP2009075651.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2009065339",
      "type": "patent",
      "title": "Japan Patent 2009-065339: Device, system, method and program for generating print data",
      "authors": null,
      "venue": "Japan Patent",
      "year": 2009,
      "pdf": "http://www.freepatentsonline.com/JP2009065339.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_us20090183114",
      "type": "patent",
      "title": "US Patent Application 20090183114: Information processing apparatus and computer program product",
      "authors": null,
      "venue": "US Patent Application",
      "year": 2009,
      "pdf": "http://www.freepatentsonline.com/y2009/0183114.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2009169537",
      "type": "patent",
      "title": "Japan Patent 2009-169537: Information processor, symbol display method and symbol display program",
      "authors": null,
      "venue": "Japan Patent",
      "year": 2009,
      "pdf": "http://www.freepatentsonline.com/JP2009169537.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_us20090180126",
      "type": "patent",
      "title": "US Patent Application 20090180126: Information processing apparatus, method of generating document, and computer-readable recording medium",
      "authors": null,
      "venue": "US Patent Application",
      "year": 2009,
      "pdf": "http://www.freepatentsonline.com/y2009/0180126.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2009169536",
      "type": "patent",
      "title": "Japan Patent 2009-169536: Information processor, image forming apparatus, document creating method and document creating program",
      "authors": null,
      "venue": "Japan Patent",
      "year": 2009,
      "pdf": "http://www.freepatentsonline.com/JP2009169536.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2009075651",
      "type": "patent",
      "title": "Japan Patent 2009-075651: Document utilization support device, document utilization support method and document utilization support program",
      "authors": null,
      "venue": "Japan Patent",
      "year": 2009,
      "pdf": "http://www.freepatentsonline.com/JP2009075651.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_icdim08",
      "type": "paper",
      "title": "Automatic Selection of Visually Attractive Pages for Thumbnail Display in Document List View",
      "authors": "Fabrice Matulic",
      "venue": "Proc. Third International Conference on Digital Information Management (ICDIM 2008), London, UK",
      "year": 2008,
      "pdf": "pubs/ICDIM2008.pdf",
      "video": null,
      "doi": null,
      "notes": null
    },
     {
      "id": "patent_us20080115080",
      "type": "patent",
      "title": "US Patent Application 20080115080: Device, method and computer program product for information retrieval",
      "authors": null,
      "venue": "US Patent Application",
      "year": 2008,
      "pdf": "http://www.freepatentsonline.com/y2008/0115080.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2008140377",
      "type": "patent",
      "title": "Japan Patent 2008-140377: Information retrieving device, method and program",
      "authors": null,
      "venue": "Japan Patent",
      "year": 2008,
      "pdf": "http://www.freepatentsonline.com/JP2008140377.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2008071311",
      "type": "patent",
      "title": "Japan Patent 2008-071311 : Image retrieval apparatus, image retrieval method, image retrieval program and information storage medium",
      "authors": null,
      "venue": "Japan Patent",
      "year": 2008,
      "pdf": "http://www.freepatentsonline.com/JP2008071311.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_doceng07",
      "type": "demo",
      "title": "Touch Scan-n-Search: A Touchscreen Interface To Retrieve Online Versions of Scanned Documents",
      "authors": "Fabrice Matulic",
      "venue": "Proc. 2007 ACM symposium on Document engineering (DocEng 2007), Winnipeg, Manitoba, Canada",
      "year": 2007,
      "pdf": "pubs/DocEng2007.pdf",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2007150858",
      "type": "patent",
      "title": "Japan Patent 2007-150858: Document editing apparatus, image forming apparatus, document editing method and program to make computer execute method",
      "authors": null,
      "venue": "Japan Patent",
      "year": 2007,
      "pdf": "http://www.freepatentsonline.com/JP2007150858.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_us20070220425",
      "type": "patent",
      "title": "US Patent Application 20070220425: Electronic mail editing device, image forming apparatus and electronic mail editing method",
      "authors": null,
      "venue": "US Patent Application",
      "year": 2007,
      "pdf": "http://www.freepatentsonline.com/y2007/0220425.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "pub_doceng06",
      "type": "demo",
      "title": "SmartPublisher - Document Creation on Pen-Based Systems Via Document Element Reuse",
      "authors": "Fabrice Matulic",
      "venue": "Proc. 2006 ACM symposium on Document engineering (DocEng 2006), Amsterdam, The Netherlands",
      "year": 2006,
      "pdf": "pubs/DocEng2006.pdf",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_us9060085",
      "type": "patent",
      "title": "Image forming apparatus, electronic mail delivery server, and information processing apparatus",
      "authors": null,
      "venue": "US Patent 9060085",
      "year": null,
      "pdf": "http://www.freepatentsonline.com/9060085.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_us8726178",
      "type": "patent",
      "title": "Device, method, and computer program product for information retrieval",
      "authors": null,
      "venue": "US Patent 8726178",
      "year": null,
      "pdf": "http://www.freepatentsonline.com/8726178.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_usapp20120224232",
      "type": "patent",
      "title": "Image Forming Apparatus, Electronic Mail Delivery Server, and Information Processing Apparatus",
      "authors": null,
      "venue": "US Patent Application 20120224232",
      "year": 2012,
      "pdf": "http://www.freepatentsonline.com/y2012/0224232.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_usapp20120162684",
      "type": "patent",
      "title": "IMAGE PROCESSING APPARATUS AND COMPUTER PROGRAM PRODUCT",
      "authors": null,
      "venue": "US Patent Application 20120162684",
      "year": 2012,
      "pdf": "http://www.freepatentsonline.com/y2012/0162684.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_us8201072",
      "type": "patent",
      "title": "Image forming apparatus, electronic mail delivery server, and information processing apparatus",
      "authors": null,
      "venue": "US Patent 8201072",
      "year": null,
      "pdf": "http://www.freepatentsonline.com/8201072.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_us8165404",
      "type": "patent",
      "title": "Method and apparatus for creating document data, and computer program product",
      "authors": null,
      "venue": "US Patent 8165404",
      "year": null,
      "pdf": "http://www.freepatentsonline.com/8165404.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_us8139257",
      "type": "patent",
      "title": "Document editing apparatus, image forming apparatus, document editing method, and computer program product",
      "authors": null,
      "venue": "US Patent 8139257",
      "year": null,
      "pdf": "http://www.freepatentsonline.com/8139257.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2011061744a",
      "type": "patent",
      "title": "IMAGE PROCESSING APPARATUS AND PROGRAM",
      "authors": null,
      "venue": "JP Patent Application 2011061744A",
      "year": 2011,
      "pdf": "http://www.freepatentsonline.com/JP2011061744A.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_wo2011030931a1",
      "type": "patent",
      "title": "IMAGE PROCESSING APPARATUS AND COMPUTER PROGRAM PRODUCT",
      "authors": null,
      "venue": "WO Patent Application 2011/030931A1",
      "year": 2011,
      "pdf": "http://www.freepatentsonline.com/WO2011030931A1.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2009169537a",
      "type": "patent",
      "title": "INFORMATION PROCESSOR, SYMBOL DISPLAY METHOD AND SYMBOL DISPLAY PROGRAM",
      "authors": null,
      "venue": "JP Patent Application 2009169537A",
      "year": 2009,
      "pdf": "http://www.freepatentsonline.com/JP2009169537A.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2009169536a",
      "type": "patent",
      "title": "INFORMATION PROCESSOR, IMAGE FORMING APPARATUS, DOCUMENT CREATING METHOD, AND DOCUMENT CREATING PROGRAM",
      "authors": null,
      "venue": "JP Patent Application 2009169536A",
      "year": 2009,
      "pdf": "http://www.freepatentsonline.com/JP2009169536A.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_usapp20090183114",
      "type": "patent",
      "title": "Information processing apparatus and computer program product",
      "authors": null,
      "venue": "US Patent Application 20090183114",
      "year": 2009,
      "pdf": "http://www.freepatentsonline.com/y2009/0183114.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_usapp20090180126",
      "type": "patent",
      "title": "Information processing apparatus, method of generating document, and computer-readable recording medium",
      "authors": null,
      "venue": "US Patent Application 20090180126",
      "year": 2009,
      "pdf": "http://www.freepatentsonline.com/y2009/0180126.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2009093628a",
      "type": "patent",
      "title": "DOCUMENT DATA CREATING APPARATUS, DOCUMENT DATA CREATING METHOD AND DOCUMENT DATA CREATING PROGRAM",
      "authors": null,
      "venue": "JP Patent Application 2009093628A",
      "year": 2009,
      "pdf": "http://www.freepatentsonline.com/JP2009093628A.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2009075651a",
      "type": "patent",
      "title": "DOCUMENT UTILIZATION SUPPORT DEVICE, DOCUMENT UTILIZATION SUPPORT METHOD AND DOCUMENT UTILIZATION SUPPORT PROGRAM",
      "authors": null,
      "venue": "JP Patent Application 2009075651A",
      "year": 2009,
      "pdf": "http://www.freepatentsonline.com/JP2009075651A.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2009065339a",
      "type": "patent",
      "title": "DEVICE, SYSTEM, METHOD AND PROGRAM FOR GENERATING PRINT DATA",
      "authors": null,
      "venue": "JP Patent Application 2009065339A",
      "year": 2009,
      "pdf": "http://www.freepatentsonline.com/JP2009065339A.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_usapp20090074298",
      "type": "patent",
      "title": "METHOD AND APPARATUS FOR CREATING DOCUMENT DATA, AND COMPUTER PROGRAM PRODUCT",
      "authors": null,
      "venue": "US Patent Application 20090074298",
      "year": 2009,
      "pdf": "http://www.freepatentsonline.com/y2009/0074298.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2008140377a",
      "type": "patent",
      "title": "INFORMATION RETRIEVING DEVICE, METHOD AND PROGRAM",
      "authors": null,
      "venue": "JP Patent Application 2008140377A",
      "year": 2008,
      "pdf": "http://www.freepatentsonline.com/JP2008140377A.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_usapp20080115080",
      "type": "patent",
      "title": "DEVICE, METHOD, AND COMPUTER PROGRAM PRODUCT FOR INFORMATION RETRIEVAL",
      "authors": null,
      "venue": "US Patent Application 20080115080",
      "year": 2008,
      "pdf": "http://www.freepatentsonline.com/y2008/0115080.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2008071311a",
      "type": "patent",
      "title": "IMAGE RETRIEVAL APPARATUS, IMAGE RETRIEVAL METHOD, IMAGE RETRIEVAL PROGRAM, AND INFORMATION STORAGE MEDIUM",
      "authors": null,
      "venue": "JP Patent Application 2008071311A",
      "year": 2008,
      "pdf": "http://www.freepatentsonline.com/JP2008071311A.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2007288769a",
      "type": "patent",
      "title": "IMAGE FORMING APPARATUS, ELECTRONIC MAIL DELIVERY SERVER AND INFORMATION PROCESSING APPARATUS",
      "authors": null,
      "venue": "JP Patent Application 2007288769A",
      "year": 2007,
      "pdf": "http://www.freepatentsonline.com/JP2007288769A.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_usapp20070230778",
      "type": "patent",
      "title": "Image forming apparatus, electronic mail delivery server, and information processing apparatus",
      "authors": null,
      "venue": "US Patent Application 20070230778",
      "year": 2007,
      "pdf": "http://www.freepatentsonline.com/y2007/0230778.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2007257044a",
      "type": "patent",
      "title": "E-MAIL PREPARATION DEVICE AND METHOD, AND PROGRAM MAKING COMPUTER EXECUTE THE METHOD",
      "authors": null,
      "venue": "JP Patent Application 2007257044A",
      "year": 2007,
      "pdf": "http://www.freepatentsonline.com/JP2007257044A.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2007249429a",
      "type": "patent",
      "title": "EMAIL EDITING DEVICE, IMAGE FORMING DEVICE, EMAIL EDITING METHOD, AND PROGRAM MAKING COMPUTER EXECUTE THE METHOD",
      "authors": null,
      "venue": "JP Patent Application 2007249429A",
      "year": 2007,
      "pdf": "http://www.freepatentsonline.com/JP2007249429A.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_usapp20070220425",
      "type": "patent",
      "title": "ELECTRONIC MAIL EDITING DEVICE, IMAGE FORMING APPARATUS, AND ELECTRONIC MAIL EDITING METHOD",
      "authors": null,
      "venue": "US Patent Application 20070220425",
      "year": 2007,
      "pdf": "http://www.freepatentsonline.com/y2007/0220425.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_usapp20070133074",
      "type": "patent",
      "title": "Document editing apparatus, image forming apparatus, document editing method, and computer program product",
      "authors": null,
      "venue": "US Patent Application 20070133074",
      "year": 2007,
      "pdf": "http://www.freepatentsonline.com/y2007/0133074.html",
      "video": null,
      "doi": null,
      "notes": null
    },
    {
      "id": "patent_jp2007150858a",
      "type": "patent",
      "title": "DOCUMENT EDITING APPARATUS, IMAGE FORMING APPARATUS, DOCUMENT EDITING METHOD, AND PROGRAM TO MAKE COMPUTER EXECUTE METHOD",
      "authors": null,
      "venue": "JP Patent Application 2007150858A",
      "year": 2007,
      "pdf": "http://www.freepatentsonline.com/JP2007150858A.html",
      "video": null,
      "doi": null,
      "notes": null
    }
  ],

  "projects": [
    {
      "id": "proj_hci4ml",
      "title": "HCI for Machine Learning",
      "description": "Preparing and preprocessing source data to train neural networks can require considerable manual labour and expertise. We create intuitive user interfaces and techniques to facilitate some of those tasks, including data labelling and augmentation.",
      "images": [
        "projects/proj_hci4ml/MultiviewCapture.jpg",
        "projects/proj_hci4ml/DataAugment.jpg"
      ],
      "institution_id": "pfn",
      "categories": ["hci", "ml", "cv"],
      "publication_ids": ["pub_siggraphasia23tc", "pub_iss23", "pub_chi23lbw2"]
    },
    {
      "id": "proj_dexterous",
      "title": "Dexterous Finger Gestures to Manipulate Mobile Phones",
      "description": "This research explores single-handed \"dexterous gestures\" for manipulating a mobile phone using fine motor skills of fingers. We consider four dexterous manipulations: shift, spin, rotate, and flip, which we analyse in three user studies. We provide design guidelines to map gestures to interactions and show how they can be used in applications.",
      "images": ["projects/proj_dexterous/PhoneDexterity.png"],
      "institution_id": "pfn",
      "categories": ["hci", "mobile", "embodied"],
      "publication_ids": ["pub_chi23"]
    },
    {
      "id": "proj_hybridvr",
      "title": "Pen+Touch+Midair Hybrid Two-Hand Interaction in desktop VR",
      "description": "We explore a design space for hybrid bimanual pen and touch input extended to midair interaction in desktop-based virtual reality, specifically, asymmetric interaction patterns combining the pen with the other hand when interacting in the same “space” (either surface or midair), across both spaces, and with cross-space transitions (from surface to midair and vice versa). We concretely investigate those interactions and associated gestures with three testbed applications for 3D modelling, volumetric rendering, and terrain editing.",
      "images": [
        "projects/proj_hybridvr/PenTouchMidair.png",
        "projects/proj_hybridvr/VRTerrainModelling.jpg"
      ],
      "institution_id": "pfn",
      "categories": ["pen-touch", "xr", "embodied", "hci"],
      "publication_ids": ["pub_gi23", "pub_chi22lbw"]
    },
    {
      "id": "proj_typealike",
      "title": "Typealike: Near-Keyboard Hand Postures for Expanded Laptop Interaction",
      "description": "Typealike is a style of hand postures close to natural typing poses that allow users to quickly trigger commands on a laptop computer. The hand postures are detected using deep learning classification of images captured by the laptop's webcam reflected through a downward-facing mirror.",
      "images": ["projects/proj_typealike/Typealike.png"],
      "institution_id": "pfn",
      "categories": ["hci", "ml", "cv", "embodied"],
      "publication_ids": ["pub_iss21a"]
    },
    {
      "id": "proj_phonevr",
      "title": "Mobile Phones as VR Controllers with Above-Screen Mirrors to Capture and Track Hands for Visualisation in VR",
      "description": "Smartphones can be used as VR controllers but since the user cannot see the phone or their hands when wearing the headset, precise touch input is difficult. We address this problem by attaching one or two mirrors above the phone screen such that the front-facing camera captures the hand through reflection. With a single mirror the camera feed can be shown directly as a texture on the screen of the phone model in VR to help the user aim precisely with their fingers. With two mirrors capturing the hand from two different angles, we can track the 3D position of fingertips using deep learning.",
      "images": [
        "projects/proj_phonevr/Phonetroller.jpg",
        "projects/proj_phonevr/PhoneVR2.jpg"
      ],
      "institution_id": "pfn",
      "categories": ["xr", "mobile", "cv", "hci", "ml"],
      "publication_ids": ["pub_chi21", "pub_chi23lbw", "pub_gi24"]
    },
    {
      "id": "proj_pensight",
      "title": "PenSight: Enhancing Pen Interaction via a Pen-Top Camera",
      "description": "PenSight is a novel concept to enhance pen interaction on tablets using a fisheye-lens camera attached to the top of the pen and facing downwards. Thus, the camera can \"see\" the user's hands and the surrounding environment. Using deep learning, we can detect different hand postures and tablet grips for quick action triggers and capturing off-tablet content such as surrounding documents.",
      "images": ["projects/proj_pensight/PenSight.jpg"],
      "institution_id": "pfn",
      "categories": ["pen-touch", "cv", "ml", "hci"],
      "publication_ids": ["pub_chi20", "pub_springer21"]
    },
    {
      "id": "proj_penemg",
      "title": "Elicitation of Alternative Pen-Holding Postures for Quick Action Triggers with Suitability for EMG Armband Detection",
      "description": "In this project we study what alternative ways of gripping a digital pen people might choose to trigger actions and shortcuts in applications (e.g. while holding the pen, extend the pinkie to invoke a menu). We also investigate how well we can recognise these different pen-holding postures using data collected from an EMG armband and deep learning.",
      "images": ["projects/proj_penemg/PenEMGIcon.jpg"],
      "institution_id": "pfn",
      "categories": ["pen-touch", "ml", "hci", "embodied"],
      "publication_ids": ["pub_iss19", "pub_springer21"]
    },
    {
      "id": "proj_hri",
      "title": "Human-Robot Interaction for Personal Robots",
      "description": "Smart domestic robots are poised to revolutionise the way household chores and everyday tasks are carried out in the home of the future. Thanks to the recent boom of deep learning and \"artificial intelligence\", machines are able to autonomously perform increasingly complex tasks. But no matter how smart these robots may be or become, humans still need to engage with them and it is paramount that such interactions occur smoothly and safely. Our research efforts in human-robot interaction aim to not only better support end users (customers) when operating robots in their home, but also facilitate the programming and training of these machines by engineers, technicians and developers.",
      "images": ["projects/proj_hri/HayateGesture.jpg"],
      "institution_id": "pfn",
      "categories": ["hci", "robotics", "ml"],
      "publication_ids": ["pub_chi19lbw", "pub_chi19hcmlws"]
    },
    {
      "id": "proj_colouraize",
      "title": "ColourAIze: AI-Driven Colourisation of Paper Drawings with Interactive Projection System",
      "description": "ColourAIze is an interactive system that analyses black and white drawings on paper, automatically determines realistic colour fills using AI and projects those colours onto the paper within the line art. In addition to selecting between multiple colouring styles, the user can specify local colour preferences to the AI via simple stylus strokes in desired areas of the drawing. This allows users to immediately and directly view potential colour fills for paper sketches or published black and white artwork such as comics.",
      "images": ["projects/proj_colouraize/ColourAIze.jpg"],
      "institution_id": "pfn",
      "categories": ["hci", "cv", "ml", "projection"],
      "publication_ids": ["pub_iss18"]
    },
    {
      "id": "proj_unimanualpt",
      "title": "Single-Hand Pen and Touch Input Using Variations of Pen-Holding Grips",
      "description": "This work investigates the use of different pen-holding grips while writing and drawing on a tablet to trigger various actions, including changing the pen function (e.g. to select, scroll, search) and calling in-place menus. The postures are recognised when the hand contacts the surface using a deep convolutional neural network applied on the raw touch input data (the capactitive image of the tablet). The feasibility of this approach is confirmed by two user evaluations.",
      "images": ["projects/proj_unimanualpt/UnimanualPT.jpg"],
      "institution_id": "pfn",
      "categories": ["pen-touch", "hci", "ml", "cv"],
      "publication_ids": ["pub_uist18", "pub_springer21"]
    },
    {
      "id": "proj_hybridpointing",
      "title": "HybridPointing for Touch: Switching Between Absolute and Relative Pointing on Large Touch Screens",
      "description": "CursorTap is a multitouch selection technique to efficiently reach both near and distant targets on large wall displays using hybrid absolute and relative pointing. The user switches to relative mode with three-fingers of one hand while using the other hand to control a cursor, similar to a touchpad.",
      "images": ["projects/proj_hybridpointing/HybridPointing.png"],
      "institution_id": "waterloo",
      "categories": ["hci", "large-displays", "touch"],
      "publication_ids": ["pub_iss21b"]
    },
    {
      "id": "proj_modeswitchvr",
      "title": "Barehand Mid-air Mode-Switching Techniques in VR",
      "description": "This work presents an empirical comparison of bare hand, mid-air mode-switching techniques suitable for virtual reality (VR). Specifically, we look at what kind of hand/finger postures can efficiently change the type of operation performed by the same action of the dominant hand (e.g. from moving a virtual object with a finger translation to scaling or copying it). We consider common finger and hand motions such as pinching fingers, turning and waving the hand(s)) as switching techniques. Our results provide guidance to researchers and practitioners when choosing or designing bare hand, mid-air mode-switching techniques in VR.",
      "images": ["projects/proj_modeswitchvr/ModeSwitchVR.jpg"],
      "institution_id": "waterloo",
      "categories": ["xr", "hci", "embodied", "evaluation"],
      "publication_ids": ["pub_chi19"]
    },
    {
      "id": "proj_multiray",
      "title": "Multiray: Multi-Finger Raycasting for Large Vertical Displays",
      "description": "Multiray is a concept that extends single raycasting for interacting with distant vertical displays to multi-finger raycasting, that is, each finger projects a ray onto the remote display. In particular, with multirays, patterns of ray intersections created by hand postures can form 2D geometric shapes to trigger actions and perform direct manipulations that go beyond single-point selections.",
      "images": ["projects/proj_multiray/Multiray.jpg"],
      "institution_id": "waterloo",
      "categories": ["hci", "large-displays", "embodied"],
      "publication_ids": ["pub_chi18"]
    },
    {
      "id": "proj_modeswitchtouch",
      "title": "Experimental Analysis of Mode Switching Techniques in Touch-based User Interfaces",
      "description": "This project looks at the performance of switching between different functions or modes for touch input (the possibility to rapidly change the output produced by the same touch action). Six techniques are evaluated in sitting and standing conditions: long press, non-dominant hand, two-fingers, hard press, knuckle, and thumb-on-finger. Our work addresses the lack of empirical evidence on the efficiency of touch mode-switching techniques and provides guidance to practitioners and researchers when designing new mode-switching methods.",
      "images": ["projects/proj_modeswitchtouch/Modeswitch.jpg"],
      "institution_id": "waterloo",
      "categories": ["hci", "touch", "evaluation"],
      "publication_ids": ["pub_chi17"]
    },
    {
      "id": "proj_handposturewidgets",
      "title": "Hand and Finger Posture-Based Calling and Control of Tabletop Widgets",
      "description": "Tabletop interaction can be enriched by considering whole hands as input instead of only fingertips. In this work, we propose a straightforward, easily reproducible computer vision algorithm to recognise hand contact shapes from the raw touch contact image. The technique is able to discard resting arms and supports dynamic properties such as finger movement and hover. The algorithm is used to trigger, parameterise, and dynamically control menu and tool widgets.",
      "images": ["projects/proj_handposturewidgets/PalmFingersFanMenu.jpg"],
      "institution_id": "imld",
      "categories": ["hci", "touch", "cv", "tabletop"],
      "publication_ids": ["pub_iss17"]
    },
    {
      "id": "proj_embodiedpres",
      "title": "Embodied Interactions for Novel Immersive Presentational Experiences",
      "description": "This project is about enhancing live multimedia presentations by integrating presenters in their presentation content as interactive avatars. Using multimodal input, especially body gestures, presenters control those embedded avatars through which they can interact with the virtual presentation environment in a fine-grained fashion, i.e. they are able to manipulate individual presentation elements and data as virtual props. The goal of this endeavour is to create novel immersive presentational experiences for live stage performances (talks, lectures etc.) as well as for remote conferencing in more confined areas such as offices and meeting rooms.",
      "images": ["projects/proj_embodiedpres/EmbeddedPres.jpg"],
      "institution_id": "imld",
      "categories": ["hci", "xr", "embodied", "presentation"],
      "publication_ids": ["pub_chi16lbw_eip"]
    },
    {
      "id": "proj_smartproj",
      "title": "Smart Ubiquitous Projection: Discovering Adequate Surfaces for the Projection of Adaptive Content",
      "description": "In this work, we revisit the concept of ubuiquitous projection, where instead of considering every physical surface and object as a display, we seek to determine areas that are suitable for the projection and interaction with digital information. We achieve this using mobile projector-cameras units (procams) and a computer vision technique to automatically detect rectangular surface regions with properties that are desirable for projection (uniform, pale, non-reflective, planar etc.). In a next step, we explore body-based interactions to adaptively lay out content in those recognised areas.",
      "images": ["projects/proj_smartproj/SmartProj.jpg"],
      "institution_id": "imld",
      "categories": ["hci", "cv", "projection", "ubiquitous", "embodied"],
      "publication_ids": ["pub_chi16lbw_sp"]
    },
    {
      "id": "proj_bodylenses",
      "title": "BodyLenses – Embodied Magic Lenses and Personal Territories for Wall Displays",
      "description": "Magic lenses are popular tools to provide locally altered views of visual data. In this work, we introduce the concept of BodyLenses, special kinds of magic lenses for wall displays that are mainly controlled by body interactions. Using body position, arm gestures, distance to the display and classic multitouch on the screen, we show how parameters such as lens position, shape, function and tool selection can be dynamically and intuitively modified by users.",
      "images": ["projects/proj_bodylenses/BodyLenses.jpg"],
      "institution_id": "imld",
      "categories": ["hci", "large-displays", "embodied", "visualization"],
      "publication_ids": ["pub_its15bl"]
    },
    {
      "id": "proj_msrsensing",
      "title": "Sensing Techniques for Tablet+Stylus Interaction",
      "description": "Using a special grip- and motion-sensitive stylus and a grip-sensitive tablet, we explore a range of novel pen and touch interactions including detecting how the user holds the pen and the tablet, distinguishing between the pen-holding hand and the bare hand, discarding touches caused by resting palms while writing (palm rejection) and a number of contextual gestures resulting from the detection of those different postures.",
      "images": ["projects/proj_msrsensing/MSRGripSensing.jpg"],
      "institution_id": "msr",
      "categories": ["pen-touch", "hci", "sensing", "embodied"],
      "publication_ids": ["pub_uist14"]
    },
    {
      "id": "proj_eyesfreewb",
      "title": "Handheld Devices as Eyes-Free Touch Toolboxes for Pen-Based Interactive Whiteboards",
      "description": "In this project, we investigate how smartphones can be used as portable quick-access toolboxes held by the non-dominant hand to provide assistive touch commands for pen-driven whiteboard tasks. In particular, we consider an eyes-free UI design, which allows users to operate the handheld device in a blind manner, i.e. without having to look at it, thereby allowing them to concentrate on the pen task.",
      "images": ["projects/proj_eyesfreewb/Eyes-free_whiteboard.jpg"],
      "institution_id": "eth",
      "categories": ["pen-touch", "hci", "mobile", "whiteboard"],
      "publication_ids": ["pub_its15wb"]
    },
    {
      "id": "proj_spatialquery",
      "title": "Pen-Based Spatial Queries on Interactive Maps",
      "description": "In this work, we present and evaluate a set of pen-based techniques to annotate maps on tablets or interactive tabletops and selectively convert those annotations into spatial queries allowing users to search for points of interests within explicitly or implicitly specified scopes, e.g. look for restaurants, hotels etc. within circled areas or along sketched paths or calculated routes.",
      "images": ["projects/proj_spatialquery/PTMap.jpg"],
      "institution_id": "eth",
      "categories": ["pen-touch", "hci", "gis", "visualization"],
      "publication_ids": ["pub_its14"]
    },
    {
      "id": "proj_docengtabletop",
      "title": "Document Engineering on Pen and Touch Tabletops",
      "description": "Digital tabletops operated using hybrid pen and touch input provide rich interaction possibilities. As interactive workdesks within the office of the future, they stand to support knowledge workers in a number of productivity tasks, many of which are likely to involve documents. This project aims to leverage the potential of those systems to support document-centric activities, especially the editing and authoring of documents. In particular, the practicality of post-WIMP designs based on bimanual gestures is explored.",
      "images": [
        "projects/proj_docengtabletop/PTEditor.jpg",
        "projects/proj_docengtabletop/AR_application2.jpg"
      ],
      "institution_id": "eth",
      "categories": ["doc-eng", "pen-touch", "hci", "tabletop"],
      "publication_ids": ["pub_thesis14", "pub_its13", "pub_chi13ws", "pub_chi13wip", "pub_uist12ds", "pub_avi12"]
    },
    {
      "id": "proj_ptproperties",
      "title": "Properties of Pen and Touch Input",
      "description": "Combined bimanual pen and touch input is a relatively new interaction paradigm with promising prospects. Its properties are not yet well understood and hence merit to be studied. This project experimentally investigates and reports on some important issues of pen and touch input on horizontal surfaces, including aspects of speed, accuracy and coordination.",
      "images": ["projects/proj_ptproperties/PTProperties.png"],
      "institution_id": "eth",
      "categories": ["pen-touch", "hci", "evaluation", "tabletop"],
      "publication_ids": ["pub_its12"]
    },
    {
      "id": "proj_adaptiveweb",
      "title": "Adaptive Web-Page Layout for Large Screens",
      "description": "The vast majority of web pages adapt very poorly to large displays, especially widescreens. We propose techniques to produce and evaluate adaptive web pages using web standards (and especially features of HTML5 and CSS3). We address issues such as multi-column layouts, scale-dependent element selection and positioning, font size, line lengths etc.",
      "images": ["projects/proj_adaptiveweb/AdaptiveWP.jpg"],
      "institution_id": "eth",
      "categories": ["doc-eng", "hci", "web", "large-displays"],
      "publication_ids": ["pub_doceng11", "pub_chi11"]
    },
    {
      "id": "proj_salientpages",
      "title": "Automatic Extraction of Visually Salient Pages of Large Documents",
      "description": "This technique attempts to automatically select a given number of pages from a document that visually \"stand out\" with a view to including them in a document list with thumbnails of sample pages (e.g. a catalogue or an online book store). The algorithm considers a set of low-level features such as element block sizes and tone saliency to determine pages that are more likely to attract attention. A smoothing function is available to inject some level of spread in the culling process.",
      "images": ["projects/proj_salientpages/SalientPages.png"],
      "institution_id": "eth",
      "categories": ["doc-eng", "cv", "hci"],
      "publication_ids": ["pub_jdim09", "pub_icdim08"]
    },
    {
      "id": "proj_touchscansearch",
      "title": "Touch Scan-n-Search: A Touchscreen Interface To Retrieve Online Versions of Scanned Documents",
      "description": "This system tackles the problem of finding online content based on paper documents through an intuitive touchscreen interface designed for modern scanners and multifunction printers. Touch Scan-n-Search allows the user to select elements of a scanned document (e.g. a newspaper article) and seamlessly connect to common web search services in order to retrieve the online version of the document along with related content. This is achieved by automatically extracting keyphrases from text elements in the document (obtained by OCR) and creating tappable GUI widgets to allow the user to control and fine-tune the search requests.",
      "images": ["projects/proj_touchscansearch/TouchScanSearch.jpg"],
      "institution_id": "ricoh",
      "categories": ["doc-eng", "hci", "cv", "ocr", "touch"],
      "publication_ids": ["pub_doceng07"]
    },
    {
      "id": "proj_smartpublisher",
      "title": "SmartPublisher - Document Creation on Pen-Based Systems Via Document Element Reuse",
      "description": "SmartPublisher is a powerful, all-in-one application for pen-based devices with which users can quickly and intuitively create new documents by reusing individual image and text elements acquired from analogue and/or digital documents. The application is especially targeted at scanning devices with touch screen operating panels or tablet PCs connected to them (e.g. modern multifunction printers with large touch screen displays), as one of its main purposes is reuse of material obtained from scanned paper documents.",
      "images": ["projects/proj_smartpublisher/SmartPublisher.jpg"],
      "institution_id": "ricoh",
      "categories": ["doc-eng", "pen-touch", "hci"],
      "publication_ids": ["pub_doceng06"]
    },
    {
      "id": "proj_layoutrec",
      "title": "Document Layout Recognition and Template Matching",
      "description": "This system allows the user to draw rough frames with a stylus or use a scanned drawing to create placeholders for content to be inserted in (e.g. photos for a photo album). Based on the hand-drawn shapes, queries to search for matching templates can also be issued. The user can then select an appropriate template and automatically map content to its placeholders.",
      "images": ["projects/proj_layoutrec/LayoutTemplate.jpg"],
      "institution_id": "ricoh",
      "categories": ["doc-eng", "cv", "hci", "pen-touch"],
      "publication_ids": []
    },
    {
      "id": "proj_elementtransfer",
      "title": "Advanced UI for Efficient Document Element Transfer on High-End Multifunction Printers",
      "description": "This application designed for pen-operated multifunction printers integrates 2 modules that support users to send and share elements of scanned documents. The advanced scan2E-Mail function allows users to send only the desired portion of the scanned document as well as extracted text directly in the E-Mail body. The size and compression level of the sent content can also be adapted to the target recipient device (e.g. a mobile phone). The second module gives users the possibility to gather and send document elements to their work PC. The contents appear in a sidebar from which they can be dragged and dropped into desktop applications such as a word processor.",
      "images": ["projects/proj_elementtransfer/ContentsBar.png"],
      "institution_id": "ricoh",
      "categories": ["doc-eng", "hci", "ui", "pen-touch"],
      "publication_ids": []
    },
    {
      "id": "proj_videoprinting",
      "title": "Printing Web Pages with Embedded Videos",
      "description": "Attempting to print a web page with embedded multimedia content with a standard web browser will at best return a printout with a single frame in lieu of the video. This technique, meant as a browser plugin, extracts a number of relevant frames to be included in the printout to recover some of the lost context of the video. The result is a document containing strips of representative movie frames at the location of the video or at the end of the document.",
      "images": ["projects/proj_videoprinting/VideoPrinting.jpg"],
      "institution_id": "ricoh",
      "categories": ["doc-eng", "hci", "multimedia", "web"],
      "publication_ids": []
    },
    {
      "id": "proj_iadi",
      "title": "Interactive Animated Document Icons",
      "description": "Interactive Animated Document Icons or IADIs are full documents rendered in thumbnail size to be integrated in document lists or file browsers. Pages of an IADI can be \"turned\" following a user-defined trigger (mouse hover, wheel or keyboard). A magnifying function is also available to zoom the pages for quick previews.",
      "images": ["projects/proj_iadi/iadi_placeholder.png"],
      "institution_id": "ricoh",
      "categories": ["doc-eng", "hci", "visualization", "ui"],
      "publication_ids": []
    },
    {
      "id": "proj_doccompiler",
      "title": "Automatic Document Compiler",
      "description": "The goal of this project is to provide a comprehensive solution to gather and aggregate content relevant to the user from heterogeneous sources (e.g. news articles about a particular topic) and compile the elements into a single coherent document with an appropriate layout. Several criteria are considered to define the constraints used to produce the layout: user preferences, target medium constraints, aesthetic layout rules and semantic similarity between items.",
      "images": ["projects/proj_doccompiler/DocumentCompiler.jpg"],
      "institution_id": "ricoh",
      "categories": ["doc-eng", "hci", "ml", "ai"],
      "publication_ids": []
    },
    {
      "id": "proj_elementsearch",
      "title": "Document Element Extraction and Search",
      "description": "This work deals with the extraction of document components from existing office documents in order to populate a database of reusable elements. Those elements can then be retrieved via an ad hoc web interface (using keywords, but also content-based searching) and inserted into new documents.",
      "images": ["projects/proj_elementsearch/SmartNavi.png"],
      "institution_id": "ricoh",
      "categories": ["doc-eng", "hci", "search"],
      "publication_ids": []
    }
  ],
  "patents": [
    {
      "id": "patent1",
      "title": "Interactive System for Blended Physical and Digital Content",
      "number": "US Patent 9,XXX,XXX",
      "date": "2018-05-15",
      "url": "https://patents.google.com/patent/US9XXXXXXB2/en"
    },
    {
      "id": "patent2",
      "title": "Method and Apparatus for Multi-user Interaction in Mixed Reality",
      "number": "JP Patent XXXX",
      "date": "2024-01-20"
    }
  ],
  "contact": {
    "email": "your.email [at] example.com",
    "linkedin": "https://linkedin.com/in/yourprofile",
    "google_scholar": "https://scholar.google.com/citations?user=YOUR_ID",
    "address": "Optional Address Line 1<br>Optional Address Line 2"
  },
  "ui_text": {
      "publications": "Publications:",
      "pdf": "PDF",
      "video": "Video",
      "doi": "DOI",
      "institution": "Institution:",
      "view_project": "View Project Details",
      "tab_projects": "Projects",
      "tab_publications": "Publications",
      "all_publications_title": "All Publications (Chronological)"
  }
}